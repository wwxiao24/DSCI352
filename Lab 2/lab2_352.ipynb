{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 2: classification methods\n",
    "\n",
    "This lab is due by midnight Saturday Feb 19th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You will need to change this for your environment\n",
    "DATA_ROOT = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the 'index_col' argument here, which makes slicing easier below.\n",
    "market = pd.read_csv(DATA_ROOT + 'Smarket.csv', index_col=0, parse_dates=True)\n",
    "market.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Sat, 12 Feb 2022   Deviance:                       1727.6\n",
      "Time:                                          16:11:05   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4                                         \n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n",
      "predicted probabilities: [0.49291587 0.51853212 0.51886117 0.48477764 0.48921884 0.49304354\n",
      " 0.50734913 0.49077084 0.48238647 0.51116222]\n",
      "qualitative predictions: ['Up', 'Down', 'Down', 'Up', 'Up', 'Up', 'Down', 'Up', 'Up', 'Down']\n",
      "confusion matrix:\n",
      " [[145 141]\n",
      " [457 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.507     0.241     0.327       602\n",
      "          Up      0.526     0.782     0.629       648\n",
      "\n",
      "    accuracy                          0.522      1250\n",
      "   macro avg      0.516     0.512     0.478      1250\n",
      "weighted avg      0.517     0.522     0.483      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will re-use this formula with other learning methods below\n",
    "all_lags = 'Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume'\n",
    "\n",
    "marklr = smf.glm(formula=all_lags, data=market, family=sm.families.Binomial())\n",
    "mlr_res = marklr.fit()\n",
    "print(mlr_res.summary())\n",
    "\n",
    "# The predicted values are probabilities\n",
    "mlr_prob = mlr_res.predict()\n",
    "print('predicted probabilities:', mlr_prob[0:10])\n",
    "\n",
    "# Here we create a set of qualitative predictions by thresholding on the probabilities\n",
    "predictions_nominal = [\"Up\" if x < 0.5 else \"Down\" for x in mlr_prob]\n",
    "print('qualitative predictions:', predictions_nominal[0:10])\n",
    "\n",
    "# Note: the '.T' here to take the transpose so that the true classes are columns and the predicted classes are rows,\n",
    "# matching the class slides\n",
    "print('confusion matrix:\\n', confusion_matrix(market[\"Direction\"], predictions_nominal).T)\n",
    "\n",
    "print(classification_report(market[\"Direction\"], predictions_nominal, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets, training on everything up to and including 2004 data\n",
    "# and testing on 2005 and later data:\n",
    "x_train = market[:'2004'][:]\n",
    "y_train = market[:'2004']['Direction']\n",
    "\n",
    "x_test = market['2005':][:]\n",
    "y_test = market['2005':]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                  998\n",
      "Model:                                              GLM   Df Residuals:                      991\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -690.55\n",
      "Date:                                  Sat, 12 Feb 2022   Deviance:                       1381.1\n",
      "Time:                                          16:16:57   Pearson chi2:                     998.\n",
      "No. Iterations:                                       4                                         \n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1912      0.334     -0.573      0.567      -0.845       0.463\n",
      "Lag1           0.0542      0.052      1.046      0.295      -0.047       0.156\n",
      "Lag2           0.0458      0.052      0.884      0.377      -0.056       0.147\n",
      "Lag3          -0.0072      0.052     -0.139      0.889      -0.108       0.094\n",
      "Lag4          -0.0064      0.052     -0.125      0.901      -0.108       0.095\n",
      "Lag5           0.0042      0.051      0.083      0.934      -0.096       0.104\n",
      "Volume         0.1163      0.240      0.485      0.628      -0.353       0.586\n",
      "==============================================================================\n",
      "confusion matrix:\n",
      " [[77 97]\n",
      " [34 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.69      0.54       111\n",
      "          Up       0.56      0.31      0.40       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.50      0.50      0.47       252\n",
      "weighted avg       0.51      0.48      0.46       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression to the training data and (below) evaluate it using the test data\n",
    "mlr_04 = smf.glm(formula=all_lags, data=x_train, family=sm.families.Binomial())\n",
    "res_04 = mlr_04.fit()\n",
    "print(res_04.summary())\n",
    "\n",
    "# Build predictions of the test data using a 0.5 threshold\n",
    "prob_04 = res_04.predict(x_test)\n",
    "pred_04 = ['Up' if x < 0.5 else 'Down' for x in prob_04]\n",
    "\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_04).T)\n",
    "print(classification_report(y_test, pred_04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Your job: build and test a LR model with only the two predictors with the best p-values above\n",
    "\n",
    "Looking at the model summary above, that will be Lag1 and Lag2.\n",
    "\n",
    "Build the new model below, and generate a new confusion matrix and classification report as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                  998\n",
      "Model:                                              GLM   Df Residuals:                      995\n",
      "Model Family:                                  Binomial   Df Model:                            2\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -690.70\n",
      "Date:                                  Sat, 12 Feb 2022   Deviance:                       1381.4\n",
      "Time:                                          16:17:18   Pearson chi2:                     998.\n",
      "No. Iterations:                                       4                                         \n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0322      0.063     -0.508      0.611      -0.156       0.092\n",
      "Lag1           0.0556      0.052      1.076      0.282      -0.046       0.157\n",
      "Lag2           0.0445      0.052      0.861      0.389      -0.057       0.146\n",
      "==============================================================================\n",
      "confusion matrix:\n",
      " [[ 35  35]\n",
      " [ 76 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.32      0.39       111\n",
      "          Up       0.58      0.75      0.66       141\n",
      "\n",
      "    accuracy                           0.56       252\n",
      "   macro avg       0.54      0.53      0.52       252\n",
      "weighted avg       0.55      0.56      0.54       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a model using just lag1 and lag2 and test it (skip the code for the lab)\n",
    "\n",
    "slr = smf.glm(formula='Direction ~ Lag1 + Lag2', data=x_train, family=sm.families.Binomial())\n",
    "slr_fit = slr.fit()\n",
    "print(slr_fit.summary())\n",
    "prob_slr = slr_fit.predict(x_test)\n",
    "pred_slr = ['Up' if x < 0.5 else 'Down' for x in prob_slr]\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_slr).T)\n",
    "print(classification_report(y_test, pred_slr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions 1 - 3\n",
    "\n",
    "Question 1: How does the overall accuracy of this smaller model compare\n",
    "\n",
    "A:The overall accuracy of the smaller model actually seems to be better than that of the larger model.\n",
    "\n",
    "\n",
    "Question 2: Show how to use the confusion matrix to derive the overall accuracy as shown in the classification report.\n",
    "(The calculations can be typed here and do not have to be shown with code.)\n",
    "\n",
    "A:35+106/(35+35+76+106) = 55.9%\n",
    "\n",
    "\n",
    "Question 3: How does the interpretability of the second model compare with the first in your opinion? Justify your answer.\n",
    "\n",
    "A: Naturally when the amount of variables/lags decreases, the interpretability improves. Thus, when we have a model with 2 lags vs. another model with 5, and the model with 2 also has better accuracy, it strongly indicates that the other three lags were unecessary or unproductive to the efficacy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "We now build a model for the same data with K-Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Restrict the training and test data to only have the 'Lag1' and 'Lag2' predictor variables.\n",
    "# (This code fits the model and makes predictions in one line.)\n",
    "pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "\n",
    "print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix:\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.43      0.45       111\n",
      "          Up       0.58      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN with K of 1 performed poorly, let's try K of 3\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "\n",
    "print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Your task: try some more values for K (number of neighbors) and report on which has best overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "KNN confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "2\n",
      "KNN confusion matrix:\n",
      " [[74 93]\n",
      " [37 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.67      0.53       111\n",
      "          Up       0.56      0.34      0.42       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.50      0.50      0.48       252\n",
      "weighted avg       0.51      0.48      0.47       252\n",
      "\n",
      "3\n",
      "KNN confusion matrix:\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.43      0.45       111\n",
      "          Up       0.58      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "4\n",
      "KNN confusion matrix:\n",
      " [[71 82]\n",
      " [40 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.64      0.54       111\n",
      "          Up       0.60      0.42      0.49       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.53      0.53      0.51       252\n",
      "weighted avg       0.54      0.52      0.51       252\n",
      "\n",
      "5\n",
      "KNN confusion matrix:\n",
      " [[40 59]\n",
      " [71 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.36      0.38       111\n",
      "          Up       0.54      0.58      0.56       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.47      0.47      0.47       252\n",
      "weighted avg       0.48      0.48      0.48       252\n",
      "\n",
      "6\n",
      "KNN confusion matrix:\n",
      " [[63 79]\n",
      " [48 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.57      0.50       111\n",
      "          Up       0.56      0.44      0.49       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.50      0.50       252\n",
      "\n",
      "7\n",
      "KNN confusion matrix:\n",
      " [[41 65]\n",
      " [70 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.39      0.37      0.38       111\n",
      "          Up       0.52      0.54      0.53       141\n",
      "\n",
      "    accuracy                           0.46       252\n",
      "   macro avg       0.45      0.45      0.45       252\n",
      "weighted avg       0.46      0.46      0.46       252\n",
      "\n",
      "8\n",
      "KNN confusion matrix:\n",
      " [[63 82]\n",
      " [48 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.57      0.49       111\n",
      "          Up       0.55      0.42      0.48       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.49      0.49      0.48       252\n",
      "weighted avg       0.50      0.48      0.48       252\n",
      "\n",
      "9\n",
      "KNN confusion matrix:\n",
      " [[45 61]\n",
      " [66 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.41      0.41       111\n",
      "          Up       0.55      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.49      0.50      0.49       252\n",
      "\n",
      "10\n",
      "KNN confusion matrix:\n",
      " [[67 77]\n",
      " [44 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.60      0.53       111\n",
      "          Up       0.59      0.45      0.51       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.53      0.53      0.52       252\n",
      "weighted avg       0.54      0.52      0.52       252\n",
      "\n",
      "11\n",
      "KNN confusion matrix:\n",
      " [[50 57]\n",
      " [61 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.45      0.46       111\n",
      "          Up       0.58      0.60      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "12\n",
      "KNN confusion matrix:\n",
      " [[64 75]\n",
      " [47 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.58      0.51       111\n",
      "          Up       0.58      0.47      0.52       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.52      0.52       252\n",
      "\n",
      "13\n",
      "KNN confusion matrix:\n",
      " [[46 60]\n",
      " [65 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.41      0.42       111\n",
      "          Up       0.55      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "14\n",
      "KNN confusion matrix:\n",
      " [[53 79]\n",
      " [58 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.48      0.44       111\n",
      "          Up       0.52      0.44      0.48       141\n",
      "\n",
      "    accuracy                           0.46       252\n",
      "   macro avg       0.46      0.46      0.46       252\n",
      "weighted avg       0.47      0.46      0.46       252\n",
      "\n",
      "15\n",
      "KNN confusion matrix:\n",
      " [[42 61]\n",
      " [69 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.38      0.39       111\n",
      "          Up       0.54      0.57      0.55       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.47      0.47      0.47       252\n",
      "weighted avg       0.48      0.48      0.48       252\n",
      "\n",
      "16\n",
      "KNN confusion matrix:\n",
      " [[49 77]\n",
      " [62 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.39      0.44      0.41       111\n",
      "          Up       0.51      0.45      0.48       141\n",
      "\n",
      "    accuracy                           0.45       252\n",
      "   macro avg       0.45      0.45      0.45       252\n",
      "weighted avg       0.46      0.45      0.45       252\n",
      "\n",
      "17\n",
      "KNN confusion matrix:\n",
      " [[44 61]\n",
      " [67 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.40      0.41       111\n",
      "          Up       0.54      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "18\n",
      "KNN confusion matrix:\n",
      " [[48 71]\n",
      " [63 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.43      0.42       111\n",
      "          Up       0.53      0.50      0.51       141\n",
      "\n",
      "    accuracy                           0.47       252\n",
      "   macro avg       0.46      0.46      0.46       252\n",
      "weighted avg       0.47      0.47      0.47       252\n",
      "\n",
      "19\n",
      "KNN confusion matrix:\n",
      " [[43 55]\n",
      " [68 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.39      0.41       111\n",
      "          Up       0.56      0.61      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "20\n",
      "KNN confusion matrix:\n",
      " [[49 69]\n",
      " [62 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.44      0.43       111\n",
      "          Up       0.54      0.51      0.52       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.48      0.48      0.48       252\n",
      "\n",
      "21\n",
      "KNN confusion matrix:\n",
      " [[41 55]\n",
      " [70 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.37      0.40       111\n",
      "          Up       0.55      0.61      0.58       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "22\n",
      "KNN confusion matrix:\n",
      " [[51 63]\n",
      " [60 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.46      0.45       111\n",
      "          Up       0.57      0.55      0.56       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "23\n",
      "KNN confusion matrix:\n",
      " [[41 58]\n",
      " [70 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.37      0.39       111\n",
      "          Up       0.54      0.59      0.56       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "24\n",
      "KNN confusion matrix:\n",
      " [[51 67]\n",
      " [60 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.46      0.45       111\n",
      "          Up       0.55      0.52      0.54       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "25\n",
      "KNN confusion matrix:\n",
      " [[43 61]\n",
      " [68 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.39      0.40       111\n",
      "          Up       0.54      0.57      0.55       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.48      0.49      0.49       252\n",
      "\n",
      "26\n",
      "KNN confusion matrix:\n",
      " [[54 72]\n",
      " [57 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.49      0.46       111\n",
      "          Up       0.55      0.49      0.52       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.49      0.49       252\n",
      "\n",
      "27\n",
      "KNN confusion matrix:\n",
      " [[45 62]\n",
      " [66 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.41      0.41       111\n",
      "          Up       0.54      0.56      0.55       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "28\n",
      "KNN confusion matrix:\n",
      " [[53 75]\n",
      " [58 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.48      0.44       111\n",
      "          Up       0.53      0.47      0.50       141\n",
      "\n",
      "    accuracy                           0.47       252\n",
      "   macro avg       0.47      0.47      0.47       252\n",
      "weighted avg       0.48      0.47      0.47       252\n",
      "\n",
      "29\n",
      "KNN confusion matrix:\n",
      " [[49 63]\n",
      " [62 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.44      0.44       111\n",
      "          Up       0.56      0.55      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "30\n",
      "KNN confusion matrix:\n",
      " [[55 69]\n",
      " [56 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.50      0.47       111\n",
      "          Up       0.56      0.51      0.54       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.50      0.51       252\n",
      "\n",
      "31\n",
      "KNN confusion matrix:\n",
      " [[44 62]\n",
      " [67 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.40      0.41       111\n",
      "          Up       0.54      0.56      0.55       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "32\n",
      "KNN confusion matrix:\n",
      " [[52 69]\n",
      " [59 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.47      0.45       111\n",
      "          Up       0.55      0.51      0.53       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.49      0.49       252\n",
      "\n",
      "33\n",
      "KNN confusion matrix:\n",
      " [[42 57]\n",
      " [69 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.38      0.40       111\n",
      "          Up       0.55      0.60      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.49      0.50      0.50       252\n",
      "\n",
      "34\n",
      "KNN confusion matrix:\n",
      " [[51 68]\n",
      " [60 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.46      0.44       111\n",
      "          Up       0.55      0.52      0.53       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.49      0.49       252\n",
      "\n",
      "35\n",
      "KNN confusion matrix:\n",
      " [[43 57]\n",
      " [68 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.60      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "36\n",
      "KNN confusion matrix:\n",
      " [[51 70]\n",
      " [60 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.46      0.44       111\n",
      "          Up       0.54      0.50      0.52       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.48      0.49       252\n",
      "\n",
      "37\n",
      "KNN confusion matrix:\n",
      " [[43 60]\n",
      " [68 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.39      0.40       111\n",
      "          Up       0.54      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "38\n",
      "KNN confusion matrix:\n",
      " [[52 70]\n",
      " [59 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.47      0.45       111\n",
      "          Up       0.55      0.50      0.52       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "39\n",
      "KNN confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "40\n",
      "KNN confusion matrix:\n",
      " [[52 67]\n",
      " [59 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.47      0.45       111\n",
      "          Up       0.56      0.52      0.54       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "41\n",
      "KNN confusion matrix:\n",
      " [[43 56]\n",
      " [68 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.56      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.49      0.50      0.49       252\n",
      "weighted avg       0.50      0.51      0.50       252\n",
      "\n",
      "42\n",
      "KNN confusion matrix:\n",
      " [[51 65]\n",
      " [60 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.46      0.45       111\n",
      "          Up       0.56      0.54      0.55       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.50      0.50       252\n",
      "\n",
      "43\n",
      "KNN confusion matrix:\n",
      " [[45 56]\n",
      " [66 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.41      0.42       111\n",
      "          Up       0.56      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.52      0.51       252\n",
      "\n",
      "44\n",
      "KNN confusion matrix:\n",
      " [[51 67]\n",
      " [60 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.46      0.45       111\n",
      "          Up       0.55      0.52      0.54       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "45\n",
      "KNN confusion matrix:\n",
      " [[41 54]\n",
      " [70 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.37      0.40       111\n",
      "          Up       0.55      0.62      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.51      0.50       252\n",
      "\n",
      "46\n",
      "KNN confusion matrix:\n",
      " [[49 63]\n",
      " [62 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.44      0.44       111\n",
      "          Up       0.56      0.55      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "47\n",
      "KNN confusion matrix:\n",
      " [[41 57]\n",
      " [70 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.37      0.39       111\n",
      "          Up       0.55      0.60      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.50      0.49       252\n",
      "\n",
      "48\n",
      "KNN confusion matrix:\n",
      " [[49 65]\n",
      " [62 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.44      0.44       111\n",
      "          Up       0.55      0.54      0.54       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "49\n",
      "KNN confusion matrix:\n",
      " [[42 56]\n",
      " [69 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.38      0.40       111\n",
      "          Up       0.55      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "50\n",
      "KNN confusion matrix:\n",
      " [[47 64]\n",
      " [64 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.42      0.42       111\n",
      "          Up       0.55      0.55      0.55       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.49      0.49       252\n",
      "\n",
      "51\n",
      "KNN confusion matrix:\n",
      " [[43 55]\n",
      " [68 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.39      0.41       111\n",
      "          Up       0.56      0.61      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "52\n",
      "KNN confusion matrix:\n",
      " [[53 60]\n",
      " [58 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.48      0.47       111\n",
      "          Up       0.58      0.57      0.58       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.53      0.53      0.53       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "53\n",
      "KNN confusion matrix:\n",
      " [[39 58]\n",
      " [72 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.35      0.37       111\n",
      "          Up       0.54      0.59      0.56       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.47      0.47      0.47       252\n",
      "weighted avg       0.48      0.48      0.48       252\n",
      "\n",
      "54\n",
      "KNN confusion matrix:\n",
      " [[48 63]\n",
      " [63 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.43      0.43       111\n",
      "          Up       0.55      0.55      0.55       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "55\n",
      "KNN confusion matrix:\n",
      " [[42 58]\n",
      " [69 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.38      0.40       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.49      0.50      0.49       252\n",
      "\n",
      "56\n",
      "KNN confusion matrix:\n",
      " [[49 61]\n",
      " [62 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.44      0.44       111\n",
      "          Up       0.56      0.57      0.57       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "57\n",
      "KNN confusion matrix:\n",
      " [[41 52]\n",
      " [70 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.37      0.40       111\n",
      "          Up       0.56      0.63      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.52      0.51       252\n",
      "\n",
      "58\n",
      "KNN confusion matrix:\n",
      " [[50 59]\n",
      " [61 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.45      0.45       111\n",
      "          Up       0.57      0.58      0.58       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "59\n",
      "KNN confusion matrix:\n",
      " [[43 52]\n",
      " [68 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.39      0.42       111\n",
      "          Up       0.57      0.63      0.60       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "60\n",
      "KNN confusion matrix:\n",
      " [[50 59]\n",
      " [61 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.45      0.45       111\n",
      "          Up       0.57      0.58      0.58       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "61\n",
      "KNN confusion matrix:\n",
      " [[44 53]\n",
      " [67 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.40      0.42       111\n",
      "          Up       0.57      0.62      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "62\n",
      "KNN confusion matrix:\n",
      " [[50 60]\n",
      " [61 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.45      0.45       111\n",
      "          Up       0.57      0.57      0.57       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "63\n",
      "KNN confusion matrix:\n",
      " [[44 53]\n",
      " [67 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.40      0.42       111\n",
      "          Up       0.57      0.62      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "64\n",
      "KNN confusion matrix:\n",
      " [[49 62]\n",
      " [62 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.44      0.44       111\n",
      "          Up       0.56      0.56      0.56       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "65\n",
      "KNN confusion matrix:\n",
      " [[43 54]\n",
      " [68 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.39      0.41       111\n",
      "          Up       0.56      0.62      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.52      0.51       252\n",
      "\n",
      "66\n",
      "KNN confusion matrix:\n",
      " [[50 57]\n",
      " [61 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.45      0.46       111\n",
      "          Up       0.58      0.60      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "67\n",
      "KNN confusion matrix:\n",
      " [[47 52]\n",
      " [64 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.42      0.45       111\n",
      "          Up       0.58      0.63      0.61       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.53      0.53      0.53       252\n",
      "weighted avg       0.53      0.54      0.54       252\n",
      "\n",
      "68\n",
      "KNN confusion matrix:\n",
      " [[53 59]\n",
      " [58 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.48      0.48       111\n",
      "          Up       0.59      0.58      0.58       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.53      0.53      0.53       252\n",
      "weighted avg       0.54      0.54      0.54       252\n",
      "\n",
      "69\n",
      "KNN confusion matrix:\n",
      " [[45 52]\n",
      " [66 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.41      0.43       111\n",
      "          Up       0.57      0.63      0.60       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "70\n",
      "KNN confusion matrix:\n",
      " [[52 58]\n",
      " [59 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.47      0.47       111\n",
      "          Up       0.58      0.59      0.59       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.53      0.53      0.53       252\n",
      "weighted avg       0.54      0.54      0.54       252\n",
      "\n",
      "71\n",
      "KNN confusion matrix:\n",
      " [[46 52]\n",
      " [65 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.41      0.44       111\n",
      "          Up       0.58      0.63      0.60       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.54      0.53       252\n",
      "\n",
      "72\n",
      "KNN confusion matrix:\n",
      " [[55 59]\n",
      " [56 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.48      0.50      0.49       111\n",
      "          Up       0.59      0.58      0.59       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.54      0.54      0.54       252\n",
      "weighted avg       0.54      0.54      0.54       252\n",
      "\n",
      "73\n",
      "KNN confusion matrix:\n",
      " [[44 54]\n",
      " [67 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.40      0.42       111\n",
      "          Up       0.56      0.62      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.51      0.52      0.52       252\n",
      "\n",
      "74\n",
      "KNN confusion matrix:\n",
      " [[54 57]\n",
      " [57 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.49      0.49      0.49       111\n",
      "          Up       0.60      0.60      0.60       141\n",
      "\n",
      "    accuracy                           0.55       252\n",
      "   macro avg       0.54      0.54      0.54       252\n",
      "weighted avg       0.55      0.55      0.55       252\n",
      "\n",
      "75\n",
      "KNN confusion matrix:\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.43      0.45       111\n",
      "          Up       0.58      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "76\n",
      "KNN confusion matrix:\n",
      " [[53 61]\n",
      " [58 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.48      0.47       111\n",
      "          Up       0.58      0.57      0.57       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "77\n",
      "KNN confusion matrix:\n",
      " [[44 56]\n",
      " [67 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.40      0.42       111\n",
      "          Up       0.56      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "78\n",
      "KNN confusion matrix:\n",
      " [[50 62]\n",
      " [61 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.45      0.45       111\n",
      "          Up       0.56      0.56      0.56       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "79\n",
      "KNN confusion matrix:\n",
      " [[39 56]\n",
      " [72 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.35      0.38       111\n",
      "          Up       0.54      0.60      0.57       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.47       252\n",
      "weighted avg       0.48      0.49      0.49       252\n",
      "\n",
      "80\n",
      "KNN confusion matrix:\n",
      " [[48 63]\n",
      " [63 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.43      0.43       111\n",
      "          Up       0.55      0.55      0.55       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "81\n",
      "KNN confusion matrix:\n",
      " [[42 60]\n",
      " [69 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.41      0.38      0.39       111\n",
      "          Up       0.54      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.49       252\n",
      "   macro avg       0.48      0.48      0.48       252\n",
      "weighted avg       0.48      0.49      0.49       252\n",
      "\n",
      "82\n",
      "KNN confusion matrix:\n",
      " [[51 61]\n",
      " [60 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.46      0.46       111\n",
      "          Up       0.57      0.57      0.57       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "83\n",
      "KNN confusion matrix:\n",
      " [[46 61]\n",
      " [65 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.41      0.42       111\n",
      "          Up       0.55      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "84\n",
      "KNN confusion matrix:\n",
      " [[52 65]\n",
      " [59 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.47      0.46       111\n",
      "          Up       0.56      0.54      0.55       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.51      0.51       252\n",
      "\n",
      "85\n",
      "KNN confusion matrix:\n",
      " [[45 59]\n",
      " [66 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.41      0.42       111\n",
      "          Up       0.55      0.58      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "86\n",
      "KNN confusion matrix:\n",
      " [[47 62]\n",
      " [64 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.42      0.43       111\n",
      "          Up       0.55      0.56      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "87\n",
      "KNN confusion matrix:\n",
      " [[43 56]\n",
      " [68 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.56      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.49      0.50      0.49       252\n",
      "weighted avg       0.50      0.51      0.50       252\n",
      "\n",
      "88\n",
      "KNN confusion matrix:\n",
      " [[48 63]\n",
      " [63 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.43      0.43       111\n",
      "          Up       0.55      0.55      0.55       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "89\n",
      "KNN confusion matrix:\n",
      " [[42 55]\n",
      " [69 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.38      0.40       111\n",
      "          Up       0.55      0.61      0.58       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.51      0.50       252\n",
      "\n",
      "90\n",
      "KNN confusion matrix:\n",
      " [[51 62]\n",
      " [60 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.46      0.46       111\n",
      "          Up       0.57      0.56      0.56       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "91\n",
      "KNN confusion matrix:\n",
      " [[44 55]\n",
      " [67 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.40      0.42       111\n",
      "          Up       0.56      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.52      0.51       252\n",
      "\n",
      "92\n",
      "KNN confusion matrix:\n",
      " [[53 65]\n",
      " [58 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.45      0.48      0.46       111\n",
      "          Up       0.57      0.54      0.55       141\n",
      "\n",
      "    accuracy                           0.51       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.51      0.51       252\n",
      "\n",
      "93\n",
      "KNN confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "94\n",
      "KNN confusion matrix:\n",
      " [[54 64]\n",
      " [57 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.49      0.47       111\n",
      "          Up       0.57      0.55      0.56       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "95\n",
      "KNN confusion matrix:\n",
      " [[48 57]\n",
      " [63 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.43      0.44       111\n",
      "          Up       0.57      0.60      0.58       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n",
      "96\n",
      "KNN confusion matrix:\n",
      " [[55 64]\n",
      " [56 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.50      0.48       111\n",
      "          Up       0.58      0.55      0.56       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.52      0.53       252\n",
      "\n",
      "97\n",
      "KNN confusion matrix:\n",
      " [[47 53]\n",
      " [64 88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.42      0.45       111\n",
      "          Up       0.58      0.62      0.60       141\n",
      "\n",
      "    accuracy                           0.54       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.54      0.53       252\n",
      "\n",
      "98\n",
      "KNN confusion matrix:\n",
      " [[53 61]\n",
      " [58 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.48      0.47       111\n",
      "          Up       0.58      0.57      0.57       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "99\n",
      "KNN confusion matrix:\n",
      " [[46 55]\n",
      " [65 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.41      0.43       111\n",
      "          Up       0.57      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.51      0.51      0.51       252\n",
      "weighted avg       0.52      0.52      0.52       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# That was an improvement, try some other values to compare\n",
    "\n",
    "for k in range(1,100,1):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "    print(k)\n",
    "    print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 4:\n",
    "\n",
    "Question 4: Which of the other K values that you tried for K-Nearest neighbors worked the best, based on overall accuracy?\n",
    "\n",
    "A: The highest accuracy I observed was for k=74, with an accuracy of 0.55. Others, such as k=71 and k=67 and k=97 had accuracy of 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.49198397 0.50801603]\n",
      "Means: [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n",
      "Coefficients: [[-0.05544078 -0.0443452 ]]\n",
      "[[ 35  76]\n",
      " [ 35 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.32      0.39       111\n",
      "          Up       0.58      0.75      0.66       141\n",
      "\n",
      "    accuracy                           0.56       252\n",
      "   macro avg       0.54      0.53      0.52       252\n",
      "weighted avg       0.55      0.56      0.54       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "ldm = lda.fit(x_train[['Lag1', 'Lag2']], y_train)\n",
    "\n",
    "print('Priors:', ldm.priors_)\n",
    "print('Means:', ldm.means_)\n",
    "print('Coefficients:', ldm.coef_)\n",
    "\n",
    "pred = ldm.predict(x_test[['Lag1', 'Lag2']])\n",
    "print(confusion_matrix(pred, y_test).T)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.49198397 0.50801603]\n",
      "Means: [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n",
      "[[ 30  81]\n",
      " [ 20 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.60      0.27      0.37       111\n",
      "          Up       0.60      0.86      0.71       141\n",
      "\n",
      "    accuracy                           0.60       252\n",
      "   macro avg       0.60      0.56      0.54       252\n",
      "weighted avg       0.60      0.60      0.56       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdm = qda.fit(x_train[['Lag1', 'Lag2']], y_train)\n",
    "\n",
    "print('Priors:', qdm.priors_)\n",
    "print('Means:', qdm.means_)\n",
    "\n",
    "q_pred = qdm.predict(x_test[['Lag1', 'Lag2']])\n",
    "print(confusion_matrix(q_pred, y_test).T)\n",
    "print(classification_report(y_test, q_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Question 5: which of the methods that you tried produced the best results for predicting Direction from Lag1 and Lag2?\n",
    "\n",
    "A: QDA appears to have had the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carseats data\n",
    "\n",
    "Now load the carseats data and try to predict whether the store is located in the US from the other predictor variables.\n",
    "\n",
    "Report below on your findings about (at least) three different learning approaches, comparing their overall accuracy.\n",
    "\n",
    "If you use K-nearest neighbors, be sure to try a few different values for K and report on the best one, showing your work.\n",
    "\n",
    "If you use logistic regression, try to find a simple model with good accuracy by dropping predictors with high p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seats = pd.read_csv(DATA_ROOT + 'Carseats.csv')\n",
    "seats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pick random training and test sets for your analysis:\n",
    "x_train, x_test, y_train, y_test = train_test_split(seats, seats['US'],\n",
    "                                                    train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Hint: if you need to remove some predictors for training or testing in any of the learning methods,\n",
    "# you can use the pandas 'drop' function to drop the corresponding columns, e.g.\n",
    "x_train.drop(columns=['US']).head()\n",
    "\n",
    "# Hint 2: if you want to write a formula and include a lot of columns, you could use the method\n",
    "# that was shown in lab 1, e.g.:\n",
    "#sm.OLS.from_formula('medv ~ ' + '+'.join(df.columns.difference(['medv', 'age', 'indus'])), df)\n",
    "all_vals = 'US ~ Sales+CompPrice+Income+Advertising+Population+Price+ShelveLoc+Age+Education+Urban'\n",
    "dropped_vals = 'US ~ Advertising+Population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     ['US[No]', 'US[Yes]']   No. Observations:                  320\n",
      "Model:                               GLM   Df Residuals:                      308\n",
      "Model Family:                   Binomial   Df Model:                           11\n",
      "Link Function:                     logit   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -78.553\n",
      "Date:                   Sat, 12 Feb 2022   Deviance:                       157.11\n",
      "Time:                           18:11:59   Pearson chi2:                     286.\n",
      "No. Iterations:                        8                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept              -2.5350      2.499     -1.014      0.310      -7.433       2.363\n",
      "ShelveLoc[T.Good]      -1.2362      1.114     -1.110      0.267      -3.419       0.946\n",
      "ShelveLoc[T.Medium]    -0.0898      0.629     -0.143      0.886      -1.323       1.143\n",
      "Urban[T.Yes]            0.1294      0.469      0.276      0.782      -0.789       1.048\n",
      "Sales                   0.2087      0.195      1.073      0.283      -0.173       0.590\n",
      "CompPrice              -0.0151      0.026     -0.574      0.566      -0.067       0.036\n",
      "Income                 -0.0055      0.008     -0.722      0.470      -0.021       0.009\n",
      "Advertising            -0.7780      0.108     -7.222      0.000      -0.989      -0.567\n",
      "Population              0.0047      0.002      2.909      0.004       0.002       0.008\n",
      "Price                   0.0122      0.022      0.553      0.580      -0.031       0.056\n",
      "Age                     0.0274      0.015      1.778      0.075      -0.003       0.058\n",
      "Education               0.1065      0.082      1.305      0.192      -0.053       0.266\n",
      "=======================================================================================\n",
      "confusion matrix:\n",
      " [[24  9]\n",
      " [ 1 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.96      0.83        25\n",
      "         Yes       0.98      0.84      0.90        55\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.85      0.90      0.86        80\n",
      "weighted avg       0.90      0.88      0.88        80\n",
      "\n",
      "----------------------------\n",
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     ['US[No]', 'US[Yes]']   No. Observations:                  320\n",
      "Model:                               GLM   Df Residuals:                      317\n",
      "Model Family:                   Binomial   Df Model:                            2\n",
      "Link Function:                     logit   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -82.637\n",
      "Date:                   Sat, 12 Feb 2022   Deviance:                       165.27\n",
      "Time:                           18:11:59   Pearson chi2:                     463.\n",
      "No. Iterations:                        8                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.7927      0.357      2.222      0.026       0.093       1.492\n",
      "Advertising    -0.7336      0.095     -7.707      0.000      -0.920      -0.547\n",
      "Population      0.0043      0.002      2.870      0.004       0.001       0.007\n",
      "===============================================================================\n",
      "confusion matrix:\n",
      " [[24  9]\n",
      " [ 1 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.96      0.83        25\n",
      "         Yes       0.98      0.84      0.90        55\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.85      0.90      0.86        80\n",
      "weighted avg       0.90      0.88      0.88        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here. I would recommend using a different cell for each learning method:\n",
    "\n",
    "# learning method 1\n",
    "# using all values in linear regression to see which predictors to drop\n",
    "mlr_04 = smf.glm(formula=all_vals, data=x_train, family=sm.families.Binomial())\n",
    "res_04 = mlr_04.fit()\n",
    "print(res_04.summary())\n",
    "\n",
    "# Build predictions of the test data using a 0.5 threshold\n",
    "prob_04 = res_04.predict(x_test)\n",
    "pred_04 = ['Yes' if x < 0.5 else 'No' for x in prob_04]\n",
    "\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_04).T)\n",
    "print(classification_report(y_test, pred_04))\n",
    "print(\"----------------------------\")\n",
    "\n",
    "mlr_04 = smf.glm(formula=dropped_vals, data=x_train, family=sm.families.Binomial())\n",
    "res_04 = mlr_04.fit()\n",
    "print(res_04.summary())\n",
    "\n",
    "# Build predictions of the test data using a 0.5 threshold\n",
    "prob_04 = res_04.predict(x_test)\n",
    "pred_04 = ['Yes' if x < 0.5 else 'No' for x in prob_04]\n",
    "\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_04).T)\n",
    "print(classification_report(y_test, pred_04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "KNN confusion matrix:\n",
      " [[23 10]\n",
      " [ 5 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.70      0.82      0.75        28\n",
      "         Yes       0.89      0.81      0.85        52\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.80      0.81      0.80        80\n",
      "weighted avg       0.82      0.81      0.82        80\n",
      "\n",
      "2\n",
      "KNN confusion matrix:\n",
      " [[28 15]\n",
      " [ 0 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.65      1.00      0.79        28\n",
      "         Yes       1.00      0.71      0.83        52\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.83      0.86      0.81        80\n",
      "weighted avg       0.88      0.81      0.82        80\n",
      "\n",
      "3\n",
      "KNN confusion matrix:\n",
      " [[24 10]\n",
      " [ 4 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.71      0.86      0.77        28\n",
      "         Yes       0.91      0.81      0.86        52\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.81      0.83      0.82        80\n",
      "weighted avg       0.84      0.82      0.83        80\n",
      "\n",
      "4\n",
      "KNN confusion matrix:\n",
      " [[25 18]\n",
      " [ 3 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.58      0.89      0.70        28\n",
      "         Yes       0.92      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.75      0.77      0.73        80\n",
      "weighted avg       0.80      0.74      0.74        80\n",
      "\n",
      "5\n",
      "KNN confusion matrix:\n",
      " [[22 12]\n",
      " [ 6 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.65      0.79      0.71        28\n",
      "         Yes       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.78        80\n",
      "   macro avg       0.76      0.78      0.76        80\n",
      "weighted avg       0.79      0.78      0.78        80\n",
      "\n",
      "6\n",
      "KNN confusion matrix:\n",
      " [[23 17]\n",
      " [ 5 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.57      0.82      0.68        28\n",
      "         Yes       0.88      0.67      0.76        52\n",
      "\n",
      "    accuracy                           0.73        80\n",
      "   macro avg       0.72      0.75      0.72        80\n",
      "weighted avg       0.77      0.72      0.73        80\n",
      "\n",
      "7\n",
      "KNN confusion matrix:\n",
      " [[15 15]\n",
      " [13 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.54      0.52        28\n",
      "         Yes       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.62      0.62      0.62        80\n",
      "weighted avg       0.66      0.65      0.65        80\n",
      "\n",
      "8\n",
      "KNN confusion matrix:\n",
      " [[19 16]\n",
      " [ 9 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.54      0.68      0.60        28\n",
      "         Yes       0.80      0.69      0.74        52\n",
      "\n",
      "    accuracy                           0.69        80\n",
      "   macro avg       0.67      0.69      0.67        80\n",
      "weighted avg       0.71      0.69      0.69        80\n",
      "\n",
      "9\n",
      "KNN confusion matrix:\n",
      " [[14 11]\n",
      " [14 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.56      0.50      0.53        28\n",
      "         Yes       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.69        80\n",
      "   macro avg       0.65      0.64      0.65        80\n",
      "weighted avg       0.68      0.69      0.68        80\n",
      "\n",
      "10\n",
      "KNN confusion matrix:\n",
      " [[19 12]\n",
      " [ 9 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.61      0.68      0.64        28\n",
      "         Yes       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.71      0.72      0.72        80\n",
      "weighted avg       0.75      0.74      0.74        80\n",
      "\n",
      "11\n",
      "KNN confusion matrix:\n",
      " [[12 11]\n",
      " [16 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.52      0.43      0.47        28\n",
      "         Yes       0.72      0.79      0.75        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.62      0.61      0.61        80\n",
      "weighted avg       0.65      0.66      0.65        80\n",
      "\n",
      "12\n",
      "KNN confusion matrix:\n",
      " [[15 14]\n",
      " [13 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.52      0.54      0.53        28\n",
      "         Yes       0.75      0.73      0.74        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.63      0.63      0.63        80\n",
      "weighted avg       0.67      0.66      0.66        80\n",
      "\n",
      "13\n",
      "KNN confusion matrix:\n",
      " [[10 11]\n",
      " [18 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.48      0.36      0.41        28\n",
      "         Yes       0.69      0.79      0.74        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.59      0.57      0.57        80\n",
      "weighted avg       0.62      0.64      0.62        80\n",
      "\n",
      "14\n",
      "KNN confusion matrix:\n",
      " [[13 14]\n",
      " [15 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.48      0.46      0.47        28\n",
      "         Yes       0.72      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.60      0.60      0.60        80\n",
      "weighted avg       0.63      0.64      0.64        80\n",
      "\n",
      "15\n",
      "KNN confusion matrix:\n",
      " [[ 8 12]\n",
      " [20 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.40      0.29      0.33        28\n",
      "         Yes       0.67      0.77      0.71        52\n",
      "\n",
      "    accuracy                           0.60        80\n",
      "   macro avg       0.53      0.53      0.52        80\n",
      "weighted avg       0.57      0.60      0.58        80\n",
      "\n",
      "16\n",
      "KNN confusion matrix:\n",
      " [[12 14]\n",
      " [16 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.46      0.43      0.44        28\n",
      "         Yes       0.70      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.58      0.58      0.58        80\n",
      "weighted avg       0.62      0.62      0.62        80\n",
      "\n",
      "17\n",
      "KNN confusion matrix:\n",
      " [[ 6  8]\n",
      " [22 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.21      0.29        28\n",
      "         Yes       0.67      0.85      0.75        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.55      0.53      0.52        80\n",
      "weighted avg       0.58      0.62      0.58        80\n",
      "\n",
      "18\n",
      "KNN confusion matrix:\n",
      " [[ 9 10]\n",
      " [19 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.47      0.32      0.38        28\n",
      "         Yes       0.69      0.81      0.74        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.58      0.56      0.56        80\n",
      "weighted avg       0.61      0.64      0.62        80\n",
      "\n",
      "19\n",
      "KNN confusion matrix:\n",
      " [[ 5 10]\n",
      " [23 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.33      0.18      0.23        28\n",
      "         Yes       0.65      0.81      0.72        52\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.49      0.49      0.48        80\n",
      "weighted avg       0.54      0.59      0.55        80\n",
      "\n",
      "20\n",
      "KNN confusion matrix:\n",
      " [[ 6 11]\n",
      " [22 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.35      0.21      0.27        28\n",
      "         Yes       0.65      0.79      0.71        52\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.50      0.50      0.49        80\n",
      "weighted avg       0.55      0.59      0.56        80\n",
      "\n",
      "21\n",
      "KNN confusion matrix:\n",
      " [[ 4 10]\n",
      " [24 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.29      0.14      0.19        28\n",
      "         Yes       0.64      0.81      0.71        52\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.46      0.48      0.45        80\n",
      "weighted avg       0.51      0.57      0.53        80\n",
      "\n",
      "22\n",
      "KNN confusion matrix:\n",
      " [[ 5 10]\n",
      " [23 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.33      0.18      0.23        28\n",
      "         Yes       0.65      0.81      0.72        52\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.49      0.49      0.48        80\n",
      "weighted avg       0.54      0.59      0.55        80\n",
      "\n",
      "23\n",
      "KNN confusion matrix:\n",
      " [[ 5 10]\n",
      " [23 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.33      0.18      0.23        28\n",
      "         Yes       0.65      0.81      0.72        52\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.49      0.49      0.48        80\n",
      "weighted avg       0.54      0.59      0.55        80\n",
      "\n",
      "24\n",
      "KNN confusion matrix:\n",
      " [[ 5 10]\n",
      " [23 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.33      0.18      0.23        28\n",
      "         Yes       0.65      0.81      0.72        52\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.49      0.49      0.48        80\n",
      "weighted avg       0.54      0.59      0.55        80\n",
      "\n",
      "25\n",
      "KNN confusion matrix:\n",
      " [[ 4  7]\n",
      " [24 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.36      0.14      0.21        28\n",
      "         Yes       0.65      0.87      0.74        52\n",
      "\n",
      "    accuracy                           0.61        80\n",
      "   macro avg       0.51      0.50      0.47        80\n",
      "weighted avg       0.55      0.61      0.56        80\n",
      "\n",
      "26\n",
      "KNN confusion matrix:\n",
      " [[ 4  8]\n",
      " [24 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.33      0.14      0.20        28\n",
      "         Yes       0.65      0.85      0.73        52\n",
      "\n",
      "    accuracy                           0.60        80\n",
      "   macro avg       0.49      0.49      0.47        80\n",
      "weighted avg       0.54      0.60      0.55        80\n",
      "\n",
      "27\n",
      "KNN confusion matrix:\n",
      " [[ 4  6]\n",
      " [24 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.40      0.14      0.21        28\n",
      "         Yes       0.66      0.88      0.75        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.53      0.51      0.48        80\n",
      "weighted avg       0.57      0.62      0.56        80\n",
      "\n",
      "28\n",
      "KNN confusion matrix:\n",
      " [[ 5  8]\n",
      " [23 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.38      0.18      0.24        28\n",
      "         Yes       0.66      0.85      0.74        52\n",
      "\n",
      "    accuracy                           0.61        80\n",
      "   macro avg       0.52      0.51      0.49        80\n",
      "weighted avg       0.56      0.61      0.57        80\n",
      "\n",
      "29\n",
      "KNN confusion matrix:\n",
      " [[ 4  7]\n",
      " [24 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.36      0.14      0.21        28\n",
      "         Yes       0.65      0.87      0.74        52\n",
      "\n",
      "    accuracy                           0.61        80\n",
      "   macro avg       0.51      0.50      0.47        80\n",
      "weighted avg       0.55      0.61      0.56        80\n",
      "\n",
      "30\n",
      "KNN confusion matrix:\n",
      " [[ 5  9]\n",
      " [23 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.36      0.18      0.24        28\n",
      "         Yes       0.65      0.83      0.73        52\n",
      "\n",
      "    accuracy                           0.60        80\n",
      "   macro avg       0.50      0.50      0.48        80\n",
      "weighted avg       0.55      0.60      0.56        80\n",
      "\n",
      "31\n",
      "KNN confusion matrix:\n",
      " [[ 4  5]\n",
      " [24 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.44      0.14      0.22        28\n",
      "         Yes       0.66      0.90      0.76        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.55      0.52      0.49        80\n",
      "weighted avg       0.59      0.64      0.57        80\n",
      "\n",
      "32\n",
      "KNN confusion matrix:\n",
      " [[ 4  7]\n",
      " [24 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.36      0.14      0.21        28\n",
      "         Yes       0.65      0.87      0.74        52\n",
      "\n",
      "    accuracy                           0.61        80\n",
      "   macro avg       0.51      0.50      0.47        80\n",
      "weighted avg       0.55      0.61      0.56        80\n",
      "\n",
      "33\n",
      "KNN confusion matrix:\n",
      " [[ 4  4]\n",
      " [24 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.14      0.22        28\n",
      "         Yes       0.67      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.53      0.50        80\n",
      "weighted avg       0.61      0.65      0.58        80\n",
      "\n",
      "34\n",
      "KNN confusion matrix:\n",
      " [[ 4  6]\n",
      " [24 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.40      0.14      0.21        28\n",
      "         Yes       0.66      0.88      0.75        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.53      0.51      0.48        80\n",
      "weighted avg       0.57      0.62      0.56        80\n",
      "\n",
      "35\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "36\n",
      "KNN confusion matrix:\n",
      " [[ 3  5]\n",
      " [25 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.38      0.11      0.17        28\n",
      "         Yes       0.65      0.90      0.76        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.51      0.51      0.46        80\n",
      "weighted avg       0.56      0.62      0.55        80\n",
      "\n",
      "37\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "38\n",
      "KNN confusion matrix:\n",
      " [[ 3  5]\n",
      " [25 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.38      0.11      0.17        28\n",
      "         Yes       0.65      0.90      0.76        52\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.51      0.51      0.46        80\n",
      "weighted avg       0.56      0.62      0.55        80\n",
      "\n",
      "39\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "40\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "41\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "42\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "43\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "44\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "45\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "46\n",
      "KNN confusion matrix:\n",
      " [[ 3  4]\n",
      " [25 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.43      0.11      0.17        28\n",
      "         Yes       0.66      0.92      0.77        52\n",
      "\n",
      "    accuracy                           0.64        80\n",
      "   macro avg       0.54      0.52      0.47        80\n",
      "weighted avg       0.58      0.64      0.56        80\n",
      "\n",
      "47\n",
      "KNN confusion matrix:\n",
      " [[ 2  2]\n",
      " [26 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.07      0.12        28\n",
      "         Yes       0.66      0.96      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.45        80\n",
      "weighted avg       0.60      0.65      0.55        80\n",
      "\n",
      "48\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "49\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "50\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "51\n",
      "KNN confusion matrix:\n",
      " [[ 2  2]\n",
      " [26 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.07      0.12        28\n",
      "         Yes       0.66      0.96      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.45        80\n",
      "weighted avg       0.60      0.65      0.55        80\n",
      "\n",
      "52\n",
      "KNN confusion matrix:\n",
      " [[ 3  3]\n",
      " [25 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.11      0.18        28\n",
      "         Yes       0.66      0.94      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.52      0.48        80\n",
      "weighted avg       0.61      0.65      0.57        80\n",
      "\n",
      "53\n",
      "KNN confusion matrix:\n",
      " [[ 2  1]\n",
      " [26 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.67      0.07      0.13        28\n",
      "         Yes       0.66      0.98      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.66      0.53      0.46        80\n",
      "weighted avg       0.66      0.66      0.56        80\n",
      "\n",
      "54\n",
      "KNN confusion matrix:\n",
      " [[ 2  1]\n",
      " [26 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.67      0.07      0.13        28\n",
      "         Yes       0.66      0.98      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.66      0.53      0.46        80\n",
      "weighted avg       0.66      0.66      0.56        80\n",
      "\n",
      "55\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "56\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "57\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "58\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "59\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "60\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "61\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "62\n",
      "KNN confusion matrix:\n",
      " [[ 1  0]\n",
      " [27 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      0.04      0.07        28\n",
      "         Yes       0.66      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.83      0.52      0.43        80\n",
      "weighted avg       0.78      0.66      0.54        80\n",
      "\n",
      "63\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "64\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "66\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "67\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "68\n",
      "KNN confusion matrix:\n",
      " [[ 1  1]\n",
      " [27 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      0.04      0.07        28\n",
      "         Yes       0.65      0.98      0.78        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.58      0.51      0.43        80\n",
      "weighted avg       0.60      0.65      0.53        80\n",
      "\n",
      "69\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "70\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "71\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "72\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "73\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "74\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "75\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "76\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "77\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "78\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "79\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "81\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "82\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "83\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "84\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "85\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "86\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "87\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "88\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "89\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "90\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "91\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "92\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "93\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "94\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "95\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "96\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "97\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "98\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n",
      "99\n",
      "KNN confusion matrix:\n",
      " [[ 0  0]\n",
      " [28 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00        28\n",
      "         Yes       0.65      1.00      0.79        52\n",
      "\n",
      "    accuracy                           0.65        80\n",
      "   macro avg       0.33      0.50      0.39        80\n",
      "weighted avg       0.42      0.65      0.51        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wwxia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# learning method 2\n",
    "for k in range(1,100,1):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(x_train[['Advertising', 'Population']], y_train).predict(x_test[['Advertising', 'Population']])\n",
    "    print(k)\n",
    "    print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.35625 0.64375]\n",
      "Means: [[  0.55263158 252.80701754]\n",
      " [ 10.24271845 280.19417476]]\n",
      "[[27  1]\n",
      " [12 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.69      0.96      0.81        28\n",
      "         Yes       0.98      0.77      0.86        52\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.83      0.87      0.83        80\n",
      "weighted avg       0.88      0.84      0.84        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning method 3\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdm = qda.fit(x_train[['Advertising', 'Population']], y_train)\n",
    "\n",
    "print('Priors:', qdm.priors_)\n",
    "print('Means:', qdm.means_)\n",
    "\n",
    "q_pred = qdm.predict(x_test[['Advertising', 'Population']])\n",
    "print(confusion_matrix(q_pred, y_test).T)\n",
    "print(classification_report(y_test, q_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions 6-9\n",
    "\n",
    "(Each of the three questions below carries the same weight as the earlier questions.)\n",
    "\n",
    "Question 6: What was the first method you tried, and what was its best overall accuracy?\n",
    "\n",
    "A: Using linear regression with all the variables allowed me to drop all except for 2. The model had an overall accuracy of 0.88.\n",
    "\n",
    "\n",
    "Question 7: What was the second method you tried, and what was its best overall accuracy?\n",
    "\n",
    "A: The second method I tried was KNN. The highest accuracy I received using KNN was 0.82 with K=3.\n",
    "\n",
    "\n",
    "Question 8: What was the third method you tried, and what was its best overall accuracy?\n",
    "\n",
    "A: The third method I tried was QDA, with an accuracy of 0.84."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
